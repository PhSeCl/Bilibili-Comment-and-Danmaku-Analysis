import os
import sys
import torch
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.utils import get_emotion_label

def main():
    # 1. é…ç½®è·¯å¾„
    MODEL_PATH = PROJECT_ROOT / "trained_models"
    
    # å°è¯•è‡ªåŠ¨æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶
    raw_dir = PROJECT_ROOT / "data" / "raw"
    csv_files = list(raw_dir.glob("*.csv"))
    
    if not csv_files:
        print(f"âŒ åœ¨ {raw_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶")
        return
        
    # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ CSV æ–‡ä»¶ï¼Œæˆ–è€…æ‚¨å¯ä»¥æ‰‹åŠ¨æŒ‡å®š
    INPUT_FILE = csv_files[0]
    print(f"ğŸ“„ ä½¿ç”¨è¾“å…¥æ–‡ä»¶: {INPUT_FILE.name}")
    
    OUTPUT_FILE = PROJECT_ROOT / "data" / "processed" / f"{INPUT_FILE.stem}_predicted.csv"

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not MODEL_PATH.exists():
        print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {MODEL_PATH}")
        print("è¯·å…ˆè¿è¡Œ src/analysis/trainer.py è¿›è¡Œè®­ç»ƒï¼Œæˆ–å°†æ¨¡å‹æ–‡ä»¶æ”¾å…¥ trained_models æ–‡ä»¶å¤¹ã€‚")
        return

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not INPUT_FILE.exists():
        print(f"âŒ æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        return

    # 2. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    print(f"ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH} ...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")

    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(device)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return

    # 3. åŠ è½½æ•°æ®
    print(f"ğŸ“‚ è¯»å–æ•°æ®: {INPUT_FILE} ...")
    # è‡ªåŠ¨æ£€æµ‹è¡¨å¤´ï¼Œè¿™é‡Œå‡è®¾ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼Œå¦‚æœä¸æ˜¯è¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    df = pd.read_csv(INPUT_FILE)
    
    # ç¡®ä¿æœ‰ content åˆ—
    if 'content' not in df.columns:
        print("âŒ CSV æ–‡ä»¶ä¸­ç¼ºå°‘ 'content' åˆ—ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚")
        print(f"å½“å‰åˆ—å: {df.columns.tolist()}")
        return

    print(f"âœ… åŠ è½½äº† {len(df)} æ¡è¯„è®º")

    # 4. å®šä¹‰é¢„æµ‹å‡½æ•°
    def predict_batch(texts, batch_size=32):
        model.eval()
        all_preds = []
        
        for i in tqdm(range(0, len(texts), batch_size), desc="é¢„æµ‹ä¸­"):
            batch_texts = texts[i : i + batch_size]
            # å¤„ç†éå­—ç¬¦ä¸²æ•°æ®
            batch_texts = [str(t) if pd.notna(t) else "" for t in batch_texts]
            
            inputs = tokenizer(
                batch_texts, 
                return_tensors="pt", 
                truncation=True, 
                padding=True, 
                max_length=128
            ).to(device)

            with torch.no_grad():
                logits = model(**inputs).logits
            
            preds = torch.argmax(logits, dim=-1).cpu().numpy()
            all_preds.extend(preds)
            
        return all_preds

    # 5. æ‰§è¡Œé¢„æµ‹
    print("ğŸ”® å¼€å§‹æ‰¹é‡é¢„æµ‹...")
    # æ‰¹é‡é¢„æµ‹ä»¥æé«˜é€Ÿåº¦
    predictions = predict_batch(df['content'].tolist(), batch_size=32)

    # 6. æ·»åŠ ç»“æœåˆ° DataFrame
    df['predicted_label_id'] = predictions
    df['predicted_emotion'] = df['predicted_label_id'].apply(lambda x: get_emotion_label(x, use_zh=True))

    # 7. ä¿å­˜ç»“æœ
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    print("\nğŸ‘€ é¢„è§ˆå‰ 5 æ¡ç»“æœ:")
    print(df[['content', 'predicted_emotion']].head())

if __name__ == "__main__":
    main()
