import streamlit as st
import sys
import os
from pathlib import Path
import pandas as pd
import time

# Add project root to sys.path
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.append(str(PROJECT_ROOT))

# Import project modules
try:
    from src.crawler.main_crawler import crawl_comments_by_bv, crawl_danmaku_by_bv, get_video_info
    from run_prediction import run_prediction_pipeline
    from src.visualization.distribution import plot_emotion_distribution
    from src.visualization.timeline import plot_comment_timeline
    from src.visualization.viz_geo_heatmap import plot_geo_heatmap
except ImportError as e:
    st.error(f"Import Error: {e}")
    st.stop()

# Page Config
st.set_page_config(
    page_title="Bilibili Comment Analysis",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Title
st.title("ğŸ“º Bilibili è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
st.markdown("---")

# Sidebar: Configuration
st.sidebar.header("âš™ï¸ å‚æ•°è®¾ç½®")

bv_code = st.sidebar.text_input("BV å· (ä¾‹å¦‚ BV1xx411c7mD)", value="BV1xx411c7mD")
max_pages = st.sidebar.number_input("çˆ¬å–é¡µæ•° (æ¯é¡µ20æ¡)", min_value=1, max_value=100, value=5)
max_danmaku = st.sidebar.number_input("å¼¹å¹•çˆ¬å–æ¡æ•° (0ä¸ºä¸é™åˆ¶)", min_value=0, value=1000, step=100)

st.sidebar.markdown("---")
st.sidebar.info("æç¤ºï¼šå…ˆçˆ¬å–æ•°æ®ï¼Œå†è¿›è¡Œåˆ†æã€‚")

# Main Content
col1, col2 = st.columns(2)

with col1:
    st.subheader("1. æ•°æ®é‡‡é›†")
    
    # Tabs for Comments and Danmaku
    crawl_tab1, crawl_tab2 = st.tabs(["ğŸ“ è¯„è®º", "ğŸš€ å¼¹å¹•"])
    
    with crawl_tab1:
        if st.button("ğŸ•·ï¸ å¼€å§‹çˆ¬å–è¯„è®º", use_container_width=True):
            if not bv_code:
                st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ BV å·")
            else:
                with st.spinner(f"æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯: {bv_code}..."):
                    video_info = get_video_info(bv_code)
                    
                if not video_info:
                    st.error("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ BV å·æˆ–ç½‘ç»œã€‚")
                else:
                    st.success(f"æ‰¾åˆ°è§†é¢‘ (OID: {video_info['oid']})")
                    
                    # Progress bar
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # Define a custom output path for this session
                    raw_data_path = PROJECT_ROOT / "data" / "raw" / f"comments_{bv_code}.csv"
                    
                    # Callback function for progress
                    def progress_callback(current, total, msg):
                        status_text.text(msg)
                        if total > 0:
                            progress_bar.progress(min(current / total, 1.0))
                    
                    # Run crawler
                    try:
                        count = crawl_comments_by_bv(bv_code, max_pages, str(raw_data_path), callback=progress_callback)
                        progress_bar.progress(100)
                        if count > 0:
                            st.success(f"âœ… çˆ¬å–å®Œæˆï¼å…±è·å– {count} æ¡è¯„è®ºã€‚")
                            st.session_state['current_raw_data'] = str(raw_data_path)
                            st.session_state['current_bv'] = bv_code
                        else:
                            st.warning("âš ï¸ æœªçˆ¬å–åˆ°ä»»ä½•è¯„è®ºã€‚")
                    except Exception as e:
                        st.error(f"çˆ¬å–å¤±è´¥: {e}")

    with crawl_tab2:
        if st.button("ğŸš€ å¼€å§‹çˆ¬å–å¼¹å¹•", use_container_width=True):
            if not bv_code:
                st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ BV å·")
            else:
                with st.spinner(f"æ­£åœ¨çˆ¬å–å¼¹å¹•: {bv_code}..."):
                    danmaku_path = PROJECT_ROOT / "data" / "raw" / f"danmaku_{bv_code}.csv"
                    limit = max_danmaku if max_danmaku > 0 else None
                    try:
                        count = crawl_danmaku_by_bv(bv_code, limit, str(danmaku_path))
                        if count > 0:
                            st.success(f"âœ… å¼¹å¹•çˆ¬å–å®Œæˆï¼å…± {count} æ¡ã€‚")
                            st.info(f"ä¿å­˜è·¯å¾„: {danmaku_path.name}")
                        else:
                            st.warning("âš ï¸ æœªçˆ¬å–åˆ°å¼¹å¹•ã€‚")
                    except Exception as e:
                        st.error(f"å¼¹å¹•çˆ¬å–å¤±è´¥: {e}")

with col2:
    st.subheader("2. æƒ…æ„Ÿåˆ†æ")
    
    # File Selection Logic
    raw_data_dir = PROJECT_ROOT / "data" / "raw"
    if raw_data_dir.exists():
        csv_files = list(raw_data_dir.glob("*.csv"))
        # Sort by modification time (newest first)
        csv_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        file_options = {f.name: str(f) for f in csv_files}
    else:
        file_options = {}

    selected_file_name = st.selectbox(
        "é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ–‡ä»¶:",
        options=list(file_options.keys()),
        index=0 if file_options else None,
        help="ä» data/raw ç›®å½•ä¸­é€‰æ‹©å·²çˆ¬å–çš„ CSV æ–‡ä»¶"
    )
    
    current_raw_data = file_options.get(selected_file_name) if selected_file_name else None

    if st.button("ğŸ§  å¼€å§‹åˆ†æ", disabled=not current_raw_data, use_container_width=True):
        with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹å¹¶åˆ†ææƒ…æ„Ÿ (å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)..."):
            try:
                output_csv = PROJECT_ROOT / "data" / "processed" / f"predictions_{Path(current_raw_data).stem}.csv"
                df = run_prediction_pipeline(input_path=current_raw_data, output_path=output_csv)
                
                if df is not None:
                    st.session_state['analysis_result'] = df
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                else:
                    st.error("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
            except Exception as e:
                st.error(f"è¿è¡Œå‡ºé”™: {e}")

st.markdown("---")

# Visualization Section
if 'analysis_result' in st.session_state:
    df = st.session_state['analysis_result']
    
    st.header("ğŸ“Š åˆ†æç»“æœå¯è§†åŒ–")
    
    tab1, tab2, tab3, tab4 = st.tabs(["æƒ…æ„Ÿåˆ†å¸ƒ", "æ—¶é—´è¶‹åŠ¿", "åœ°åŸŸçƒ­åŠ›å›¾", "åŸå§‹æ•°æ®"])
    
    with tab1:
        st.subheader("æ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒ")
        try:
            fig, _ = plot_emotion_distribution(df, save_path=None)
            st.pyplot(fig)
        except Exception as e:
            st.error(f"ç»˜å›¾å¤±è´¥: {e}")
            
    with tab2:
        st.subheader("æƒ…æ„Ÿéšæ—¶é—´å˜åŒ–")
        if 'date' in df.columns or 'time' in df.columns:
            # Ensure date column exists
            date_col = 'time' if 'time' in df.columns else 'date'
            try:
                # Convert to datetime if needed
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                fig_timeline, _ = plot_comment_timeline(df, date_column=date_col, freq='D')
                if fig_timeline:
                    st.pyplot(fig_timeline)
                else:
                    st.info("æ•°æ®ä¸è¶³ä»¥ç”Ÿæˆæ—¶é—´åºåˆ—å›¾ã€‚")
            except Exception as e:
                st.error(f"æ—¶é—´åºåˆ—ç»˜å›¾å¤±è´¥: {e}")
        else:
            st.warning("æ•°æ®ä¸­ç¼ºå°‘æ—¶é—´åˆ—ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾ã€‚")
            
    with tab3:
        st.subheader("è¯„è®ºç”¨æˆ·åœ°åŸŸåˆ†å¸ƒ")
        if 'ip_location' in df.columns:
            heatmap_mode = st.radio("æ˜¾ç¤ºæ¨¡å¼:", ["è¯„è®ºæ•°é‡", "æƒ…æ„Ÿå€¾å‘"], horizontal=True)
            mode_key = 'sentiment' if heatmap_mode == "æƒ…æ„Ÿå€¾å‘" else 'count'
            
            try:
                # Use a temporary file for the HTML output
                temp_html = PROJECT_ROOT / "docs" / "temp_heatmap.html"
                # Pass the DataFrame directly instead of path, and pass the mode
                c = plot_geo_heatmap(df, str(temp_html), mode=mode_key)
                if c:
                    # Render HTML in Streamlit
                    import streamlit.components.v1 as components
                    with open(temp_html, 'r', encoding='utf-8') as f:
                        html_content = f.read()
                    components.html(html_content, height=600)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾ã€‚")
            except Exception as e:
                st.error(f"çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")
        else:
            st.warning("æ•°æ®ä¸­ç¼ºå°‘ 'ip_location' åˆ—ï¼Œæ— æ³•ç”Ÿæˆåœ°åŸŸçƒ­åŠ›å›¾ã€‚")

    with tab4:
        st.subheader("è¯„è®ºæ•°æ®é¢„è§ˆ")
        st.dataframe(df[['content', 'labels', 'time']].head(100) if 'time' in df.columns else df[['content', 'labels']].head(100))
        
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†æç»“æœ (CSV)",
            data=csv,
            file_name=f"sentiment_analysis_{st.session_state.get('current_bv', 'result')}.csv",
            mime='text/csv',
        )
