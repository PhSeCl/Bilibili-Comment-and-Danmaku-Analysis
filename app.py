import streamlit as st
import sys
import os
from pathlib import Path
import pandas as pd
import time

# Add project root to sys.path
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.append(str(PROJECT_ROOT))

# Import project modules
try:
    from src.crawler.main_crawler import crawl_comments_by_bv, crawl_danmaku_by_bv, get_video_info
    from run_prediction import run_prediction_pipeline
    from src.visualization.distribution import plot_emotion_distribution
    from src.visualization.timeline import plot_comment_timeline
except ImportError as e:
    st.error(f"Import Error: {e}")
    st.stop()

# Page Config
st.set_page_config(
    page_title="Bilibili Comment Analysis",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Title
st.title("ğŸ“º Bilibili è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
st.markdown("---")

# Sidebar: Configuration
st.sidebar.header("âš™ï¸ å‚æ•°è®¾ç½®")

bv_code = st.sidebar.text_input("BV å· (ä¾‹å¦‚ BV1xx411c7mD)", value="BV1xx411c7mD")
max_pages = st.sidebar.number_input("çˆ¬å–é¡µæ•° (æ¯é¡µ20æ¡)", min_value=1, max_value=100, value=5)

st.sidebar.markdown("---")
st.sidebar.info("æç¤ºï¼šå…ˆçˆ¬å–æ•°æ®ï¼Œå†è¿›è¡Œåˆ†æã€‚")

# Main Content
col1, col2 = st.columns(2)

with col1:
    st.subheader("1. æ•°æ®é‡‡é›†")
    if st.button("ğŸ•·ï¸ å¼€å§‹çˆ¬å–è¯„è®º", use_container_width=True):
        if not bv_code:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ BV å·")
        else:
            with st.spinner(f"æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯: {bv_code}..."):
                video_info = get_video_info(bv_code)
                
            if not video_info:
                st.error("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ BV å·æˆ–ç½‘ç»œã€‚")
            else:
                st.success(f"æ‰¾åˆ°è§†é¢‘ (OID: {video_info['oid']})")
                
                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Define a custom output path for this session
                raw_data_path = PROJECT_ROOT / "data" / "raw" / f"comments_{bv_code}.csv"
                
                # Run crawler
                status_text.text("æ­£åœ¨çˆ¬å–è¯„è®º...")
                try:
                    # Note: The crawler function prints to stdout, capturing progress is hard without modifying it more.
                    # We will just run it.
                    count = crawl_comments_by_bv(bv_code, max_pages, str(raw_data_path))
                    progress_bar.progress(100)
                    if count > 0:
                        st.success(f"âœ… çˆ¬å–å®Œæˆï¼å…±è·å– {count} æ¡è¯„è®ºã€‚")
                        st.session_state['current_raw_data'] = str(raw_data_path)
                        st.session_state['current_bv'] = bv_code
                    else:
                        st.warning("âš ï¸ æœªçˆ¬å–åˆ°ä»»ä½•è¯„è®ºã€‚")
                except Exception as e:
                    st.error(f"çˆ¬å–å¤±è´¥: {e}")

with col2:
    st.subheader("2. æƒ…æ„Ÿåˆ†æ")
    
    # Check if data exists
    current_raw_data = st.session_state.get('current_raw_data')
    
    # Allow manual selection if not in session
    if not current_raw_data:
        default_path = PROJECT_ROOT / "data" / "raw" / "comments.csv"
        if default_path.exists():
            st.info(f"ä½¿ç”¨é»˜è®¤æ•°æ®: {default_path.name}")
            current_raw_data = str(default_path)
        else:
            st.warning("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆçˆ¬å–ã€‚")
    else:
        st.success(f"å°±ç»ªæ•°æ®: {Path(current_raw_data).name}")

    if st.button("ğŸ§  å¼€å§‹åˆ†æ", disabled=not current_raw_data, use_container_width=True):
        with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹å¹¶åˆ†ææƒ…æ„Ÿ (å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)..."):
            try:
                output_csv = PROJECT_ROOT / "data" / "processed" / f"predictions_{Path(current_raw_data).stem}.csv"
                df = run_prediction_pipeline(input_path=current_raw_data, output_path=output_csv)
                
                if df is not None:
                    st.session_state['analysis_result'] = df
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                else:
                    st.error("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
            except Exception as e:
                st.error(f"è¿è¡Œå‡ºé”™: {e}")

st.markdown("---")

# Visualization Section
if 'analysis_result' in st.session_state:
    df = st.session_state['analysis_result']
    
    st.header("ğŸ“Š åˆ†æç»“æœå¯è§†åŒ–")
    
    tab1, tab2, tab3 = st.tabs(["æƒ…æ„Ÿåˆ†å¸ƒ", "æ—¶é—´è¶‹åŠ¿", "åŸå§‹æ•°æ®"])
    
    with tab1:
        st.subheader("æ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒ")
        try:
            fig, _ = plot_emotion_distribution(df, save_path=None)
            st.pyplot(fig)
        except Exception as e:
            st.error(f"ç»˜å›¾å¤±è´¥: {e}")
            
    with tab2:
        st.subheader("æƒ…æ„Ÿéšæ—¶é—´å˜åŒ–")
        if 'date' in df.columns or 'time' in df.columns:
            # Ensure date column exists
            date_col = 'time' if 'time' in df.columns else 'date'
            try:
                # Convert to datetime if needed
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                fig_timeline, _ = plot_comment_timeline(df, date_column=date_col, freq='D')
                if fig_timeline:
                    st.pyplot(fig_timeline)
                else:
                    st.info("æ•°æ®ä¸è¶³ä»¥ç”Ÿæˆæ—¶é—´åºåˆ—å›¾ã€‚")
            except Exception as e:
                st.error(f"æ—¶é—´åºåˆ—ç»˜å›¾å¤±è´¥: {e}")
        else:
            st.warning("æ•°æ®ä¸­ç¼ºå°‘æ—¶é—´åˆ—ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾ã€‚")
            
    with tab3:
        st.subheader("è¯„è®ºæ•°æ®é¢„è§ˆ")
        st.dataframe(df[['content', 'labels', 'time']].head(100) if 'time' in df.columns else df[['content', 'labels']].head(100))
        
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†æç»“æœ (CSV)",
            data=csv,
            file_name=f"sentiment_analysis_{st.session_state.get('current_bv', 'result')}.csv",
            mime='text/csv',
        )
