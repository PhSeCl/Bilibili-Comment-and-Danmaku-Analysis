import requests
import time
import csv
import random
import re
import os
import json
# å¯¼å…¥é…ç½®æ–‡ä»¶
import config 

def check_cookie():
    """æ£€æŸ¥ Cookie æ˜¯å¦æœ‰æ•ˆ"""
    url = "https://api.bilibili.com/x/web-interface/nav"
    try:
        print("ğŸª æ­£åœ¨æ£€æŸ¥ Cookie çŠ¶æ€...")
        resp = requests.get(url, headers=config.HEADERS)
        data = resp.json()
        if data.get('code') == 0 and data.get('data', {}).get('isLogin'):
            print(f"âœ… Cookie æœ‰æ•ˆï¼Œå½“å‰ç”¨æˆ·: {data['data']['uname']}")
            return True
        else:
            print("âš ï¸ Cookie å·²å¤±æ•ˆæˆ–æœªç™»å½•ï¼")
            print("   (è¿™å¯èƒ½ä¼šå¯¼è‡´æ— æ³•è·å–å†å²å¼¹å¹•ï¼Œæˆ–è§¦å‘é£æ§éªŒè¯ç )")
            return False
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ Cookie æ—¶å‘ç”Ÿç½‘ç»œå¼‚å¸¸: {e}")
        return False

def get_video_info(bv):
    """é€šè¿‡BVå·è·å– oid (aid) å’Œ cid"""
    url = f"https://www.bilibili.com/video/{bv}"
    try:
        resp = requests.get(url, headers=config.HEADERS)
        # æ­£åˆ™æå– aid (å³ oid)
        aid_match = re.search(r'"aid":(\d+)', resp.text)
        # æ­£åˆ™æå– cid (å¼¹å¹•è¦ç”¨åˆ°)
        cid_match = re.search(r'"cid":(\d+)', resp.text)
        
        if aid_match and cid_match:
            return {
                "oid": aid_match.group(1),
                "cid": cid_match.group(1)
            }
        else:
            print("âŒ æ‰¾ä¸åˆ° oid æˆ– cidï¼Œè¯·æ£€æŸ¥ BV å·æˆ– Cookieã€‚")
            return None
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
        return None

# ==================== è¯„è®ºçˆ¬å–éƒ¨åˆ† ====================
def fetch_comments(oid, page):
    """è·å–å•é¡µè¯„è®º"""
    url = "https://api.bilibili.com/x/v2/reply"
    params = {
        "type": 1,
        "oid": oid,
        "sort": 2,
        "pn": page,
        "ps": 20
    }
    
    # é‡è¯•æœºåˆ¶
    max_retries = 3
    for attempt in range(max_retries):
        try:
            resp = requests.get(url, params=params, headers=config.HEADERS, timeout=10) # å¢åŠ  timeout
            data = resp.json()
            if data['code'] == 0:
                return data['data']['replies']
            elif data['code'] == 12002: # è¯„è®ºåŒºå·²å…³é—­æˆ–æ— æƒé™
                print(f"âš ï¸ è¯„è®ºåŒºå¯èƒ½å·²å…³é—­æˆ–éœ€è¦æƒé™ (Code: 12002)")
                return None
            else:
                print(f"âš ï¸ API è¿”å›é”™è¯¯ (Code: {data['code']}): {data.get('message', 'Unknown error')}")
                return None
                
        except requests.exceptions.SSLError as e:
            print(f"âš ï¸ SSL é”™è¯¯ (å°è¯• {attempt+1}/{max_retries}): {e}")
            time.sleep(2 * (attempt + 1)) # é‡åˆ° SSL é”™è¯¯å¤šç­‰ä¸€ä¼šå„¿
        except requests.exceptions.ConnectionError as e:
            print(f"âš ï¸ è¿æ¥é”™è¯¯ (å°è¯• {attempt+1}/{max_retries}): {e}")
            time.sleep(1 * (attempt + 1))
        except Exception as e:
            print(f"âŒ è·å–è¯„è®ºç¬¬ {page} é¡µå¤±è´¥: {e}")
            return None
            
    print(f"âŒ ç¬¬ {page} é¡µé‡è¯• {max_retries} æ¬¡åä»å¤±è´¥ï¼Œè·³è¿‡ã€‚")
    return None

def save_comments_to_csv(comments, filename):
    """ä¿å­˜è¯„è®º"""
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    file_exists = os.path.isfile(filename)

    # å°è¯•æ‰“å¼€ç›®æ ‡æ–‡ä»¶ï¼›å¦‚æœè¢«å ç”¨ï¼ˆä¾‹å¦‚ Excel å·²ç»æ‰“å¼€è¯¥ CSVï¼‰ï¼Œå›é€€åˆ°å¸¦æ—¶é—´æˆ³çš„å¤‡ç”¨æ–‡ä»¶
    try:
        f = open(filename, mode='a', encoding='utf-8-sig', newline='')
        opened_filename = filename
    except PermissionError:
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        ts = time.strftime('%Y%m%d_%H%M%S')
        base, ext = os.path.splitext(filename)
        alt_filename = f"{base}_{ts}{ext}"
        print(f"âš ï¸ æ— æ³•å†™å…¥ç›®æ ‡æ–‡ä»¶ï¼ˆå¯èƒ½è¢«å ç”¨ï¼‰ã€‚æ”¹å†™å…¥å¤‡ç”¨æ–‡ä»¶: {alt_filename}")
        f = open(alt_filename, mode='a', encoding='utf-8-sig', newline='')
        opened_filename = alt_filename

    with f:
        writer = csv.writer(f)
        if not file_exists:
            # è¡¨å¤´
            writer.writerow(['content', 'username', 'time', 'ip_location', 'user_level', 'likes'])
        
        count = 0
        if not comments: return 0
        for c in comments:
            if not c: continue
            content = c['content']['message']
            username = c['member']['uname']
            ctime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(c['ctime']))
            location = c.get('reply_control', {}).get('location', '')
            if location:
                location = location.replace('IPå±åœ°ï¼š', '')
            user_level = c['member']['level_info']['current_level']
            likes = c['like']
            writer.writerow([content, username, ctime, location, user_level, likes])
            count += 1
        return count

# ==================== å¼¹å¹•çˆ¬å–éƒ¨åˆ† ====================
def fetch_danmaku(cid, date):
    """è·å–æŒ‡å®šæ—¥æœŸçš„å†å²å¼¹å¹•"""
    # Bç«™å†å²å¼¹å¹•æ¥å£ (è¿”å›JSONï¼Œæ¯”XMLå¥½å¤„ç†)
    url = "https://api.bilibili.com/x/v2/dm/web/history/seg.so"
    params = {
        "type": 1,
        "oid": cid,
        "date": date
    }
    try:
        print(f"ğŸ“¡ æ­£åœ¨è¯·æ±‚ {date} çš„å¼¹å¹•...")
        resp = requests.get(url, params=params, headers=config.HEADERS)
        
        # æ³¨æ„ï¼šå¦‚æœ Cookie å¤±æ•ˆæˆ–éä¼šå‘˜ï¼Œè¿™ä¸ªæ¥å£å¯èƒ½è¿”å›ç©ºæˆ–ä¹±ç 
        # å†å²å¼¹å¹•æ¥å£è¿”å›çš„æ˜¯äºŒè¿›åˆ¶ protobuf æˆ–è€…æ˜¯ç‰¹æ®Šç¼–ç ï¼Œç®€å•å¤„ç†å¯ä»¥ç”¨ web æ¥å£
        # è¿™é‡Œå°è¯•ç”¨æ›´ç®€å•çš„ web æ¥å£ï¼Œå¦‚æœä¸è¡Œåˆ™å»ºè®®ç”¨ xml æ¥å£
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæ™®é€šå¼¹å¹•æ±  https://comment.bilibili.com/{cid}.xml (XMLæ ¼å¼)
        # ä½†ä¸ºäº†ç»Ÿä¸€ CSV æ ¼å¼ï¼Œæˆ‘ä»¬å°è¯•è§£æ JSON æ ¼å¼çš„å†å²æ¥å£ï¼ˆéœ€è¦æ­£ç¡® Cookieï¼‰
        
        # å¦‚æœç›´æ¥è¿”å›äº† JSON æ–‡æœ¬
        try:
            data = resp.json()
            if data.get('code') != 0:
                print(f"âš ï¸ æ¥å£æŠ¥é”™: {data.get('message')}")
                return None
            return data['data']['dm']
        except:
            print("âš ï¸ å“åº”ä¸æ˜¯æ ‡å‡†JSONï¼Œå°è¯•ä½¿ç”¨ XML æ¥å£æˆ–æ£€æŸ¥ Cookie æƒé™")
            return None
            
    except Exception as e:
        print(f"âŒ è·å–å¼¹å¹•å¤±è´¥: {e}")
        return None

def crawl_danmaku_xml(cid):
    """å¤‡ç”¨ï¼šçˆ¬å–å½“å‰å¼¹å¹•æ±  (XMLæ¥å£ï¼Œä¸éœ€è¦ç‰¹å®šæ—¥æœŸï¼Œæ¯”è¾ƒç¨³å®š)"""
    url = f"https://comment.bilibili.com/{cid}.xml"
    try:
        resp = requests.get(url, headers=config.HEADERS)
        resp.encoding = 'utf-8'
        # ç®€å•çš„æ­£åˆ™æå–ï¼Œä¸æƒ³å¼•å…¥ lxml åº“å¢åŠ å¤æ‚åº¦
        # æ ¼å¼: <d p="...25.87400,1,25,16777215,1670000000,0,0,0">å¼¹å¹•å†…å®¹</d>
        # på±æ€§: æ—¶é—´,æ¨¡å¼,å­—ä½“,é¢œè‰²,æ—¶é—´æˆ³,è¿æ¥æ± ,ç”¨æˆ·ID,è¡ŒID
        patterns = re.findall(r'<d p="([^"]+)">([^<]+)</d>', resp.text)
        
        results = []
        for p_attr, content in patterns:
            attrs = p_attr.split(',')
            video_time = float(attrs[0]) # è§†é¢‘å†…æ—¶é—´
            date_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(int(attrs[4])))
            uid = attrs[6] # ç”¨æˆ·Hash
            results.append({
                'time': video_time,
                'date': date_time,
                'uid': uid,
                'content': content
            })
        return results
    except Exception as e:
        print(f"âŒ XML è§£æå¤±è´¥: {e}")
        return []

def save_danmaku_to_csv(danmaku_list, filename):
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    # æ”¹ä¸ºè¦†ç›–æ¨¡å¼ 'w'
    with open(filename, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        # æ€»æ˜¯å†™å…¥è¡¨å¤´
        writer.writerow(['video_time', 'real_time', 'content', 'user_hash'])
        
        count = 0
        for d in danmaku_list:
            # è¿™é‡Œå…¼å®¹ä¸€ä¸‹ fetch_danmaku å’Œ crawl_danmaku_xml çš„è¿”å›æ ¼å¼
            # å¦‚æœæ˜¯ç”¨ XML çˆ¬çš„ï¼š
            writer.writerow([
                f"{d['time']:.2f}", 
                d['date'], 
                d['content'], 
                d['uid']
            ])
            count += 1
        return count

# ==================== å°è£…å¥½çš„è°ƒç”¨æ¥å£ ====================
def crawl_comments_by_bv(bv_code, max_pages=None, output_path=None):
    """
    æ ¹æ® BV å·çˆ¬å–è¯„è®ºçš„å°è£…å‡½æ•°
    """
    if max_pages is None:
        max_pages = config.MAX_COMMENT_PAGES
    if output_path is None:
        output_path = config.COMMENT_SAVE_PATH
        
    print(f"ğŸ¯ [API] å¼€å§‹çˆ¬å–è¯„è®º: {bv_code}, é¡µæ•°: {max_pages}")
    
    # 1. è·å–è§†é¢‘ä¿¡æ¯
    video_info = get_video_info(bv_code)
    if not video_info:
        return 0
    
    oid = video_info['oid']
    
    # 2. å¾ªç¯çˆ¬å–
    total_saved = 0
    for page in range(1, max_pages + 1):
        print(f"ğŸ“„ ç¬¬ {page} é¡µ...")
        replies = fetch_comments(oid, page)
        if not replies:
            print("âš ï¸ æœ¬é¡µæ— æ•°æ®æˆ–å·²çˆ¬å®Œã€‚")
            break
        saved_count = save_comments_to_csv(replies, filename=output_path)
        total_saved += saved_count
        time.sleep(random.uniform(1.5, 3.5))
        
    print(f"ğŸ‰ [API] è¯„è®ºçˆ¬å–ç»“æŸï¼å…± {total_saved} æ¡ã€‚")
    return total_saved

def crawl_danmaku_by_bv(bv_code, max_count=None, output_path=None):
    """
    æ ¹æ® BV å·çˆ¬å–å¼¹å¹•çš„å°è£…å‡½æ•°
    """
    if output_path is None:
        output_path = config.DANMAKU_SAVE_PATH
        
    print(f"ğŸ¯ [API] å¼€å§‹çˆ¬å–å¼¹å¹•: {bv_code}")
    
    # 1. è·å–è§†é¢‘ä¿¡æ¯
    video_info = get_video_info(bv_code)
    if not video_info:
        return 0
    
    cid = video_info['cid']
    
    # 2. çˆ¬å– XML
    danmaku_list = crawl_danmaku_xml(cid)
    
    if danmaku_list:
        if max_count:
            danmaku_list = danmaku_list[:max_count]
        
        count = save_danmaku_to_csv(danmaku_list, filename=output_path)
        print(f"ğŸ‰ [API] å¼¹å¹•çˆ¬å–ç»“æŸï¼å…± {count} æ¡ã€‚")
        return count
    else:
        print("âš ï¸ [API] æœªçˆ¬å–åˆ°å¼¹å¹•ã€‚")
        return 0

# ==================== ä¸»ç¨‹åº ====================
if __name__ == "__main__":
    # 0. æ£€æŸ¥ Cookie (æ–°å¢åŠŸèƒ½)
    check_cookie()
    print("=======================================")

    # è¿è¡Œæ—¶è¾“å…¥ BV å·ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ config ä¸­çš„å€¼ï¼‰
    bv_code = input("è¯·è¾“å…¥ BV å·ï¼ˆæŒ‰Enterä½¿ç”¨é»˜è®¤å€¼: " + config.BV_CODE + "ï¼‰ï¼š").strip()
    if not bv_code:
        bv_code = config.BV_CODE
    
    print(f"ğŸ¯ ç›®æ ‡ BV å·: {bv_code}")
    print("=======================================")
    
    # 1. è·å–åŸºç¡€ä¿¡æ¯
    video_info = get_video_info(bv_code)
    if not video_info:
        exit()
    
    oid = video_info['oid']
    cid = video_info['cid']
    print(f"âœ… è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸ [OID: {oid} | CID: {cid}]")
    
    # 2. ç”¨æˆ·é€‰æ‹©
    print("\nè¯·é€‰æ‹©è¦çˆ¬å–çš„å†…å®¹ï¼š")
    print("1. ğŸ“ è¯„è®º (Comments)")
    print("2. ğŸš€ å¼¹å¹• (Danmaku)")
    choice = input("ğŸ‘‰ è¯·è¾“å…¥æ•°å­— (1 æˆ– 2): ").strip()
    
    if choice == '1':
        # ----- çˆ¬è¯„è®º -----
        max_pages = input(f"è¯·è¾“å…¥çˆ¬å–é¡µæ•°ï¼ˆæŒ‰Enterä½¿ç”¨é»˜è®¤å€¼: {config.MAX_COMMENT_PAGES}ï¼‰ï¼š").strip()
        if max_pages:
            try:
                max_pages = int(max_pages)
            except ValueError:
                print(f"âš ï¸ è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ {config.MAX_COMMENT_PAGES}")
                max_pages = config.MAX_COMMENT_PAGES
        else:
            max_pages = config.MAX_COMMENT_PAGES
        
        # åœ¨å¼€å§‹çˆ¬å–å‰ï¼Œå°è¯•åˆ é™¤æ—§æ–‡ä»¶ä»¥å®ç°è¦†ç›–
        if os.path.exists(config.COMMENT_SAVE_PATH):
            try:
                os.remove(config.COMMENT_SAVE_PATH)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æ–‡ä»¶: {config.COMMENT_SAVE_PATH}")
            except PermissionError:
                print(f"âš ï¸ æ— æ³•åˆ é™¤æ—§æ–‡ä»¶ (å¯èƒ½è¢«å ç”¨): {config.COMMENT_SAVE_PATH}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥: {e}")

        print("\n--- å¼€å§‹çˆ¬å–è¯„è®º ---")
        total_saved = 0
        for page in range(1, max_pages + 1):
            print(f"ğŸ“„ ç¬¬ {page} é¡µ...")
            replies = fetch_comments(oid, page)
            if not replies:
                print("âš ï¸ æœ¬é¡µæ— æ•°æ®æˆ–å·²çˆ¬å®Œã€‚")
                break
            saved_count = save_comments_to_csv(replies, filename=config.COMMENT_SAVE_PATH)
            total_saved += saved_count
            time.sleep(random.uniform(1.5, 3.5))
        print(f"\nğŸ‰ è¯„è®ºçˆ¬å–ç»“æŸï¼å…± {total_saved} æ¡ã€‚")
        print(f"ğŸ“‚ ä¿å­˜è·¯å¾„: {config.COMMENT_SAVE_PATH}")

    elif choice == '2':
        # ----- çˆ¬å¼¹å¹• -----
        print("\n--- å¼€å§‹çˆ¬å–å¼¹å¹• ---")
        # è¿™é‡Œä½¿ç”¨ XML æ¥å£ï¼Œå› ä¸ºå®ƒæœ€ç¨³å®šï¼Œä¸éœ€è¦å¤ªå¤æ‚çš„ Cookie æƒé™ä¹Ÿèƒ½è·‘
        danmaku_list = crawl_danmaku_xml(cid)
        
        if danmaku_list:
            max_count = input(f"è¯·è¾“å…¥çˆ¬å–æ¡æ•°é™åˆ¶ï¼ˆä¸Šé™ {len(danmaku_list)} æ¡ï¼ŒæŒ‰Enterä½¿ç”¨æœ€å¤§å€¼ï¼‰ï¼š").strip()
            if max_count:
                try:
                    max_count = int(max_count)
                    danmaku_list = danmaku_list[:max_count]
                except ValueError:
                    print(f"âš ï¸ è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨ä¸Šé™ {len(danmaku_list)} æ¡")
            
            count = save_danmaku_to_csv(danmaku_list, filename=config.DANMAKU_SAVE_PATH)
            print(f"\nğŸ‰ å¼¹å¹•çˆ¬å–ç»“æŸï¼å…± {count} æ¡ã€‚")
            print(f"ğŸ“‚ ä¿å­˜è·¯å¾„: {config.DANMAKU_SAVE_PATH}")
        else:
            print("âš ï¸ æœªçˆ¬å–åˆ°å¼¹å¹•ï¼Œå¯èƒ½æ˜¯å¼¹å¹•æ± ä¸ºç©ºæˆ–ç½‘ç»œé—®é¢˜ã€‚")
            
            
    else:
        print("âŒ è¾“å…¥æ— æ•ˆï¼Œç¨‹åºé€€å‡ºã€‚")