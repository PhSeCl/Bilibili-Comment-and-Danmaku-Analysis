import sys
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.utils import get_emotion_label

def main():
    print("========================================")
    print("   Bilibili æƒ…æ„Ÿåˆ†æ - äº¤äº’å¼é¢„æµ‹å·¥å…·")
    print("========================================")
    print("è¯·é€‰æ‹©è¦é¢„æµ‹çš„æ•°æ®ç±»å‹:")
    print("1. comments (è¯„è®º)")
    print("2. danmaku (å¼¹å¹•)")
    
    while True:
        choice = input("è¯·è¾“å…¥æ‚¨çš„é€‰æ‹© (è¾“å…¥ comments æˆ– danmaku): ").strip().lower()
        
        if choice in ['1', 'comments', 'comment']:
            data_type = 'comment'
            break
        elif choice in ['2', 'danmaku']:
            data_type = 'danmaku'
            break
        else:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ 'comments' æˆ– 'danmaku'")

    # 1. é…ç½®è·¯å¾„
    RAW_DIR = PROJECT_ROOT / "data" / "raw"
    PROCESSED_DIR = PROJECT_ROOT / "data" / "processed"
    
    # æ ¹æ®ç±»å‹é€‰æ‹©è¾“å…¥æ–‡ä»¶
    if data_type == "comment":
        INPUT_FILE = RAW_DIR / "comments.csv"
        OUTPUT_FILE = PROCESSED_DIR / "comments_predicted.csv"
    else:
        INPUT_FILE = RAW_DIR / "danmaku.csv"
        OUTPUT_FILE = PROCESSED_DIR / "danmaku_predicted.csv"

    # 2. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not INPUT_FILE.exists():
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°å¯¹åº”æ–‡ä»¶: {INPUT_FILE}")
        print("è¯·å…ˆè¿è¡Œçˆ¬è™«è¿›è¡Œçˆ¬å–")
        return

    # 3. åŠ è½½æ¨¡å‹ (ä» model.py å¯¼å…¥)
    print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹ (æ¥è‡ª src.analysis.model)...")
    try:
        # åŠ¨æ€å¯¼å…¥ï¼Œä»¥ä¾¿åœ¨ç”¨æˆ·é€‰æ‹©åå†åŠ è½½æ¨¡å‹
        from src.analysis.model import model, tokenizer, device
        print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ src/analysis/model.py ä¸­çš„é…ç½®ï¼Œæˆ–ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ã€‚")
        return

    # 4. åŠ è½½æ•°æ®
    print(f"ğŸ“‚ è¯»å–æ•°æ®: {INPUT_FILE} ...")
    try:
        # ä½¿ç”¨ utf-8-sig è¯»å–ï¼Œè·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ
        df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig', on_bad_lines='skip')
    except Exception as e:
        print(f"âŒ è¯»å– CSV æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # ç¡®ä¿æœ‰ content åˆ—
    if 'content' not in df.columns:
        print("âŒ CSV æ–‡ä»¶ä¸­ç¼ºå°‘ 'content' åˆ—ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚")
        return

    print(f"âœ… åŠ è½½äº† {len(df)} æ¡æ•°æ®")

    # 5. å®šä¹‰æ‰¹é‡é¢„æµ‹å‡½æ•°
    def predict_batch(texts, batch_size=32):
        model.eval()
        all_preds = []
        
        # å¤„ç†ç©ºå€¼
        texts = [str(t) if pd.notna(t) else "" for t in texts]
        
        for i in tqdm(range(0, len(texts), batch_size), desc="é¢„æµ‹è¿›åº¦"):
            batch_texts = texts[i : i + batch_size]
            
            inputs = tokenizer(
                batch_texts, 
                return_tensors="pt", 
                truncation=True, 
                padding=True, 
                max_length=128
            ).to(device)

            with torch.no_grad():
                logits = model(**inputs).logits
            
            preds = torch.argmax(logits, dim=-1).cpu().numpy()
            all_preds.extend(preds)
            
        return all_preds

    # 6. æ‰§è¡Œé¢„æµ‹
    print("ğŸ”® å¼€å§‹é¢„æµ‹...")
    predictions = predict_batch(df['content'].tolist(), batch_size=32)

    # 7. æ·»åŠ ç»“æœåˆ° DataFrame
    df['predicted_label_id'] = predictions
    df['predicted_emotion'] = df['predicted_label_id'].apply(lambda x: get_emotion_label(x, use_zh=True))

    # 8. ä¿å­˜ç»“æœ
    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
    # æ˜¾å¼æŒ‡å®š mode='w' ä»¥è¦†ç›–æ—§æ–‡ä»¶
    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig', mode='w')
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    print("\nğŸ‘€ é¢„è§ˆå‰ 5 æ¡ç»“æœ:")
    print(df[['content', 'predicted_emotion']].head())

if __name__ == "__main__":
    main()
